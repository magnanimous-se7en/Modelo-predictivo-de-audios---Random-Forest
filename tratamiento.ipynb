{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df061606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error convirtiendo C:\\Users\\jlpar\\Escritorio\\preprocesamiento audios\\Mineria de datos\\clipsprueba\\common_voice_es_40198068.mp3: [WinError 2] El sistema no puede encontrar el archivo especificado\n",
      "✅ Features guardados en features_final.csv\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jlpar\\Escritorio\\preprocesamiento audios\\preprocesamiento\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "c:\\Users\\jlpar\\Escritorio\\preprocesamiento audios\\preprocesamiento\\Lib\\site-packages\\pydub\\utils.py:198: RuntimeWarning: Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\n",
      "  warn(\"Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import noisereduce as nr\n",
    "\n",
    "\n",
    "\n",
    "#AUDIO_DIR = r\"\" define ruta donde guardas tus audios\n",
    "\n",
    "TARGET_SR = 16000                        # Frecuencia de muestreo deseada (Hz) samples por segundo, para capturar         información vocal, formato ideal ya que es liviano\n",
    "DESIRED_LENGTH = 5 * TARGET_SR           # Duración fija en samples (5 segundos = 5*16000 = 80000) padding para modelos de ML\n",
    "\n",
    "\n",
    "\n",
    "def file_hash(filepath):\n",
    "    \"\"\"\n",
    "    Calcula un hash MD5 único para un archivo de audio.\n",
    "    - Sirve para identificar duplicados exactos en el dataset.\n",
    "    \"\"\"\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        return hashlib.md5(f.read()).hexdigest()\n",
    "\n",
    "\n",
    "def preprocess_audio(filepath, target_sr=TARGET_SR, desired_length=DESIRED_LENGTH):\n",
    "    \"\"\"\n",
    "    Preprocesa un archivo de audio siguiendo un pipeline:\n",
    "    1. Carga\n",
    "    2. Trimming (quita silencios iniciales y finales)\n",
    "    3. Denoise (reduce ruido de fondo)\n",
    "    4. Normalización de amplitud\n",
    "    5. Resampling (ajusta la frecuencia de muestreo a target_sr)\n",
    "    6. Padding/Truncating (ajusta longitud a desired_length)\n",
    "\n",
    "    Devuelve:\n",
    "    - x: señal de audio preprocesada (numpy array)\n",
    "    - sr: frecuencia de muestreo final\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Cargar audio con su frecuencia original\n",
    "        x, sr = librosa.load(filepath, sr=None)\n",
    "\n",
    "        # 1. Trimming → eliminar silencios, se utiliza un estandar de 35 db para eliminar silencios\n",
    "        x, _ = librosa.effects.trim(x, top_db=35)\n",
    "\n",
    "        # 2. Denoising → reducir ruido, por ejemplo sonidos de ambiente \n",
    "        x = nr.reduce_noise(y=x, sr=sr)\n",
    "\n",
    "        # 3. Normalización → amplitud uniforme\n",
    "        x = librosa.util.normalize(x)\n",
    "\n",
    "        # 4. Resampling → a TARGET_SR, se usa el target_Sr para estandarizar la frecuencia de muestreo, samples por segundo\n",
    "        if sr != target_sr:\n",
    "            x = librosa.resample(x, orig_sr=sr, target_sr=target_sr)\n",
    "\n",
    "        # 5. Padding / Truncating → duración fija de los audios\n",
    "        if len(x) < desired_length:\n",
    "            x = np.pad(x, (0, desired_length - len(x)))\n",
    "        else:\n",
    "            x = x[:desired_length]\n",
    "\n",
    "        return x, target_sr\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {filepath}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def extract_features(x, sr):\n",
    "    \"\"\"\n",
    "    Extrae características principales (features) de un audio preprocesado:\n",
    "    - Zero Crossing Rate (zcr): Cuántas veces la onda del audio cruza el cero (cambia de positivo a negativo).\n",
    "    - RMS Energy (rms): La energía promedio del audio\n",
    "    - Spectral Centroid (centroid): El “centro de gravedad” del espectro de frecuencias. Indica si el sonido tiende a ser más grave o más agudo.\n",
    "    - Spectral Rolloff (rolloff): El punto de frecuencia donde está acumulado el 85–95% de la energía del sonido. Relacionado con qué tan brilloso o apagado suena.\n",
    "\n",
    "    - MFCCs (mfcc1–mfcc13): Representa la energía global del sonido (similar a un promedio de todo el espectro).\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "\n",
    "    # Zero Crossing Rate\n",
    "    features[\"zcr\"] = np.mean(librosa.feature.zero_crossing_rate(y=x))\n",
    "\n",
    "    # RMS Energy\n",
    "    features[\"rms\"] = np.mean(librosa.feature.rms(y=x))\n",
    "\n",
    "    # Spectral Centroid\n",
    "    features[\"centroid\"] = np.mean(librosa.feature.spectral_centroid(y=x, sr=sr))\n",
    "\n",
    "    # Spectral Rolloff\n",
    "    features[\"rolloff\"] = np.mean(librosa.feature.spectral_rolloff(y=x, sr=sr))\n",
    "\n",
    "    # MFCCs (13 coeficientes)\n",
    "    mfccs = librosa.feature.mfcc(y=x, sr=sr, n_mfcc=13)\n",
    "    for i in range(1, 14):\n",
    "        features[f\"mfcc{i}\"] = np.mean(mfccs[i-1])\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def build_dataset(audio_dir=AUDIO_DIR):\n",
    "    \"\"\"\n",
    "    Construye el dataset de features a partir de los audios en una carpeta.\n",
    "\n",
    "    Pasos:\n",
    "    1. Recorrer todos los archivos de audio\n",
    "    2. Eliminar archivos vacíos y duplicados\n",
    "    3. Preprocesar audio\n",
    "    4. Extraer features\n",
    "    5. Guardar en DataFrame limpio (sin duplicados ni nulos)\n",
    "\n",
    "    Devuelve:\n",
    "    - DataFrame con los features de todos los audios\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    seen_hashes = set()   # Para detectar duplicados\n",
    "\n",
    "    for root, _, files in os.walk(audio_dir):\n",
    "        for fname in files:\n",
    "            if fname.endswith((\".wav\", \".mp3\", \".flac\")):\n",
    "                fpath = os.path.join(root, fname)\n",
    "\n",
    "                # 1. Limpieza dataset crudo → eliminar audios vacíos\n",
    "                if os.path.getsize(fpath) == 0:\n",
    "                    print(f\"⏭️ Saltando archivo vacío: {fpath}\")\n",
    "                    continue\n",
    "\n",
    "                # 2. Eliminar duplicados exactos usando hash\n",
    "                h = file_hash(fpath)\n",
    "                if h in seen_hashes:\n",
    "                    print(f\"⏭️ Saltando duplicado: {fpath}\")\n",
    "                    continue\n",
    "                seen_hashes.add(h)\n",
    "\n",
    "                # 3. Preprocesamiento\n",
    "                x, sr = preprocess_audio(fpath)\n",
    "                if x is None:\n",
    "                    continue\n",
    "\n",
    "                # 4. Extracción de features\n",
    "                feats = extract_features(x, sr)\n",
    "                feats[\"filename\"] = fname  \n",
    "                data.append(feats)\n",
    "\n",
    "    # 5. Crear DataFrame y limpieza tabular\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.drop_duplicates()   # eliminar duplicados tabulares\n",
    "    df = df.dropna()            # eliminar filas con nulos\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "df_features = build_dataset(AUDIO_DIR)\n",
    "\n",
    "# Guardar resultados en CSV\n",
    "df_features.to_csv(\"audio_features.csv\", index=False)\n",
    "\n",
    "print(\"Dataset procesado y guardado en audio_features.csv\")\n",
    "print(df_features.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "preprocesamiento",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
